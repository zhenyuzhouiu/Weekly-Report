\section{Experiments and Results}
Because I want to follow the experiment protocol of FKNet, the FKNet just use on smaple of Index Finger Knuckle of Hand Dorsal Image Database to train due to classification model. However, my model uses triplet loss, so I need positive, negative and anchor samples. Firstly, all models are pre-trained on the Finger Knuckle V1 Database, and then fine-tuning on the corresponding finger knuckle database with bigger hard margin. On the Finger Knuckle V1 Database, it contains 512 subjects, and each of subjects offer 5 finger knuckle samples. In this kind of situation, I use three samples of these five samples to pre-train my models, meanwhile, as for the rest two samples as the validation dataset.

\vspace{10pt}
I also continue to train the DeConvRFN (change the RFN-128 convolution layer with deformable convolution) and EfficientNet, the loss converged to the local minimal point. As for the EfficientNet, I change the original EfficientNetV2-S to fit my application. It has 9 stages in totally, the 9th stage is classification task with FC layer, so I replace it with convolution layer for output feature maps. Meanwhile, I delete the stage7 and stage8, and change stage3 and stage4 with stride 1. As for the RFNet, I use different loss to train the model, such as whole image rotation and shift, image blocks rotation and shift, and whole image shift. And I also compare the performance with the FKNet.\textcolor{red}{Meanwhile, for getting the original EfficientNetV2-S model performance, I also added corresponding experiments with EfficientNetV2-S. Because the EfficientNetV2-S model is a classification model, I calculate MSE of two feature vectors of last layer of model as matching score. And as for the input data, I follow the same method of FKNet, each image will rotate from $-10^{\circ}$ to $10^{\circ}$ to increase the amount of training data.}